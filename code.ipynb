{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import torch\n","import numpy as np\n","from torch import nn\n","from torchvision import utils,models,transforms,datasets\n","from torch.utils.data import DataLoader\n","import tensorflow as tf\n","import random\n","from keras.datasets import mnist,cifar10\n","import PIL\n","from PIL import Image\n","import shutil\n","from google.colab import drive\n","import torch.nn.functional as F"],"metadata":{"id":"2rMRSqL8ZgLc","executionInfo":{"status":"ok","timestamp":1711972731563,"user_tz":-330,"elapsed":10432,"user":{"displayName":"Vikram Komperla","userId":"06256429957950993843"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["(train_x,train_y),(test_x,test_y) = cifar10.load_data()\n","train_x = torch.from_numpy(train_x)\n","train_y = torch.from_numpy(train_y)\n","test_x = torch.from_numpy(test_x)\n","test_y = torch.from_numpy(test_y)\n","\n","train_x = train_x.permute([0,3,1,2]) / 255\n","train_y = train_y.squeeze(1)\n","test_x = test_x.permute([0,3,1,2]) / 255\n","test_y = test_y.squeeze(1)"],"metadata":{"id":"hW8Jjsf5g9s-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711972749336,"user_tz":-330,"elapsed":11757,"user":{"displayName":"Vikram Komperla","userId":"06256429957950993843"}},"outputId":"796667cc-46e6-4f0d-b944-9200af342664"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"code","source":["train_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COJfnSj0h0LE","executionInfo":{"status":"ok","timestamp":1711972784345,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vikram Komperla","userId":"06256429957950993843"}},"outputId":"3bb8fd57-6706-472b-b1a5-64925f655acc"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([50000, 3, 32, 32])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["train_y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0yEyIkFh6PR","executionInfo":{"status":"ok","timestamp":1711972798292,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vikram Komperla","userId":"06256429957950993843"}},"outputId":"effcdf51-eae5-4d1c-e9f7-f1751b876a16"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([50000])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["test_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKPiNbbPh-KJ","executionInfo":{"status":"ok","timestamp":1711972815540,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vikram Komperla","userId":"06256429957950993843"}},"outputId":"cd884308-c5e1-4048-cb0a-34c184494a60"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000, 3, 32, 32])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["test_y.shape"],"metadata":{"id":"b-P7O3bbiBij","executionInfo":{"status":"ok","timestamp":1711972822913,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vikram Komperla","userId":"06256429957950993843"}},"outputId":"605afbbc-506f-46e0-8f6f-5437e4b8fadd","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def tensor_to_image(tensor):\n","    transform = transforms.ToPILImage()\n","    return transform(tensor)"],"metadata":{"id":"desYUTB7Tj14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SimulatedClient():\n","    def __init__(self,client_id):\n","        self.id = client_id\n","\n","    def load_parameters(self):\n","        file_path = f\"./clients/client_{self.id}/parameters.txt\"\n","        with open(file_path, 'r') as file:\n","            for line in file:\n","                key, value = line.strip().split(': ')\n","                if key == 'battery_power':\n","                    self.battery = int(value)\n","                elif key == 'service_type':\n","                    self.comm_type = int(value)\n","                elif key == 'service_strength':\n","                    self.comm_strength = float(value)\n","                elif key == 'computing_power':\n","                    self.comp_capability = float(value)\n","\n","\n","    def create_dataloader(self):\n","        classes_name = ['Airplane','Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse','Ship','Truck']\n","        images = torch.empty(0,3,32,32)\n","        labels = torch.empty(0)\n","        count = 0\n","        data_dir = f\"/content/clients/client_{self.id}/image/\"\n","        for cls in range(len(classes_name)):\n","            dir = os.path.join(data_dir,f\"{classes_name[cls]}\")\n","            filelist = os.listdir(dir)\n","            image_files = []\n","            for file2 in filelist:\n","                if file2.lower().endswith('.png'):\n","                    image_files.append(file2)\n","            for i in image_files:\n","                image_path = os.path.join(dir,i)\n","                try:\n","                    with Image.open(image_path) as image:\n","                        transform = transforms.ToTensor()\n","                        image_tensor = transform(image)\n","                        image_tensor -= 0.5\n","                        image_tensor /= 0.5\n","                        images = torch.cat((images,image_tensor.unsqueeze(0)))\n","                        label = torch.tensor(cls)\n","                        label = label.unsqueeze(0)\n","                        labels = torch.cat((labels,label))\n","                except Exception as e:\n","                    print()\n","        dl = DataLoader((list(zip(images,labels))), batch_size = 16, shuffle = True, num_workers = 0)\n","        return dl\n","\n","    #advk\n","    def update_data(self,images,labels):\n","        classes_name = ['Airplane','Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse','Ship','Truck']\n","        try:\n","            # Your existing code for updating data using images and labels\n","\n","            # Extract the folder path from the file_path\n","            folder_path = f\"/content/clients/client_{self.id}/image/\"\n","            # folder_path = \"/\".join(file_path.split(\"/\")[:-1])\n","\n","            # Remove the folder and its contents\n","            shutil.rmtree(folder_path)\n","        except Exception as e:\n","            print(f\"Error: {e}\")\n","\n","        client_directory=f\"/content/clients/client_{self.id}/\"\n","        create_image_folder(client_directory)\n","        # Add the new data to the 'images' directories\n","        for k in range(len(images)):\n","            image = tensor_to_image(images[k])\n","            label = labels[k].data\n","            digit_folder = os.path.join(folder_path, f'{classes_name[label]}')\n","            image.save(os.path.join(digit_folder, f\"image{k}.png\"))\n","\n","\n","#advk end\n","    def train(self,model,optimizer,criterion):\n","        model.train()\n","        dataloader = self.create_dataloader()\n","        if len(dataloader) == 0:\n","            return model\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","        size = 0\n","        for data,target in dataloader:\n","            data = data\n","            target = target.long()\n","            optimizer.zero_grad()\n","\n","            output = model(data)\n","            loss = criterion(output,target)\n","            _,preds = torch.max(output,1)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * data.size(0)\n","            # print(preds,target.data)\n","            running_corrects += torch.sum(preds == target.data)\n","            size += data.size(0)\n","\n","        epoch_loss = running_loss / size\n","        epoch_acc = running_corrects.double() / size\n","\n","        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","        return model\n","\n"],"metadata":{"id":"ya6SVo5ZFSjI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_image_folder(client_directory):\n","    # Create 'image' folder within the client directory\n","    image_folder = os.path.join(client_directory, 'image')\n","    if not os.path.exists(image_folder):\n","        os.makedirs(image_folder)\n","\n","\n","    # Create folders numbered 'digit1' to 'digit10' within the 'image' folder\n","    add_digit_folders(image_folder)\n","\n","\n","def add_digit_folders(image_folder):\n","    # Add 10 'digit' folders within the 'image' folder\n","    classes_name = ['Airplane','Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse','Ship','Truck']\n","    for i in range(0, 10):\n","        digit_folder = os.path.join(image_folder, f'{classes_name[i]}')\n","        if not os.path.exists(digit_folder):\n","            os.makedirs(digit_folder)"],"metadata":{"id":"oYEAtOzPTKVB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of clients\n","num_clients = 100  # You can change this to the desired number of clients\n","\n","#creating clients\n","clients = [SimulatedClient(i) for i in range(num_clients)]"],"metadata":{"id":"B18lCHfdJ-Lo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Parent directory to store client data folders\n","parent_directory = \"clients\"\n","\n","# Create the parent directory if it doesn't exist\n","os.makedirs(parent_directory, exist_ok=True)\n","\n","classes_name = ['Airplane','Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse','Ship','Truck']\n","\n","for client_id in range(num_clients):\n","    # Generate random data for each client\n","    battery_power = random.randint(1, 100)\n","    service_type = random.randint(0, 1)\n","    service_strength = random.uniform(0,1)\n","    computing_power = random.uniform(0,1)\n","\n","    # Create a dictionary with client data\n","    client_data = {\n","        \"client_id\": client_id,\n","        \"battery_power\": battery_power,\n","        \"service_type\": service_type,\n","        \"service_strength\": service_strength,\n","        \"computing_power\": computing_power\n","    }\n","\n","\n","    # Create a folder for each client within the parent directory\n","    client_directory = os.path.join(parent_directory, f\"client_{client_id}\")\n","    os.makedirs(client_directory, exist_ok=True)\n","\n","    # Create a text file within each client folder and write data to it\n","    file_path = os.path.join(client_directory, f\"parameters.txt\")\n","    with open(file_path, 'w') as file:\n","        for key, value in client_data.items():\n","            file.write(f\"{key}: {value}\\n\")\n","\n","    create_image_folder(client_directory)\n","\n","    images_x = train_x[client_id*500:(client_id+1)*500]\n","    images_y = train_y[client_id*500:(client_id+1)*500]\n","\n","    for k in range(500):\n","        trial = images_x[k]\n","        image = tensor_to_image(trial)\n","        label = images_y[k].data\n","        digit_folder = os.path.join(client_directory, 'image', f'{classes_name[label]}')\n","        image.save(os.path.join(digit_folder, f\"image{k}.png\"))\n","\n","    # reading all data from the file\n","    clients[client_id].load_parameters()\n","\n"],"metadata":{"id":"esBzRiKpQUy7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_clients_select=20\n","def select_clients():\n","  selected_clients = random.sample(clients, num_clients_select)\n","\n","  return selected_clients"],"metadata":{"id":"eXn-4DR-HXhD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x -= 0.5\n","train_x /= 0.5\n","test_x -= 0.5\n","test_x /= 0.5\n","train_dataloader = DataLoader(list(zip(train_x,train_y)),shuffle = True, batch_size = 16)\n","val_dataloader = DataLoader(list(zip(test_x,test_y)),shuffle = True, batch_size = 16)"],"metadata":{"id":"CdNx3ABTkIwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def federated_averaging_sequential(global_model, client_model,weight):\n","\n","    # Initialize an accumulator to store the aggregated model parameters\n","    aggregated_params = {var_name: param.data*weight for var_name,param in global_model.named_parameters()}\n","\n","    # Aggregate model parameters from each client\n","    for var_name, var in client_model.named_parameters():\n","        aggregated_params[var_name] += var.data\n","\n","    # Compute the average of the model parameters\n","    averaged_params = {var_name: param / (weight+1) for var_name,param in aggregated_params.items()}\n","\n","    updated_global_model = global_model\n","    for var_name, param in updated_global_model.named_parameters():\n","        param.data = averaged_params[var_name]\n","\n","    return updated_global_model\n"],"metadata":{"id":"_YznVuoWjANh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNNModel(nn.Module):\n","\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 10, kernel_size = 5, stride = 1)\n","    self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1)\n","    self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n","    self.lin1 = nn.Linear(in_features= 10*5*5,out_features = 100)\n","    self.lin2 = nn.Linear(100,10)\n","\n","  def forward(self, x):\n","    x = F.relu(self.conv1(x))\n","    x = self.pool(x)\n","    x = F.relu(self.conv2(x))\n","    x = self.pool(x)\n","    x = torch.flatten(x,1)\n","    x = F.relu(self.lin1(x))\n","    x = self.lin2(x)\n","    return x"],"metadata":{"id":"fH2nXHs_0JSk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 50\n","client_selection = []\n","criterion_federated = nn.CrossEntropyLoss()\n","\n","model_classifier_federated = CNNModel()\n","optimizer_federated = torch.optim.SGD(model_classifier_federated.parameters(),lr = 0.01,momentum = 0.9)\n","\n","# model_classifier_federated = model_classifier_federated.cuda()\n","weight = 1\n","\n","images = train_x[25000:]\n","labels = train_y[25000:]\n","\n","for epoch in range(num_epochs):\n","    # selecting clients to train model on\n","    client_selection = select_clients()\n","    for i in clients:\n","        model = i.train(model_classifier_federated,optimizer_federated,criterion_federated)\n","\n","\n","        model_classifier_federated = federated_averaging_sequential(model_classifier_federated,model,weight)\n","\n","        # if weight != 1000:\n","            # i.update_data(images[(weight-1)*25:weight*25],labels[(weight-1)*25:weight*25])\n","        weight += 1\n","\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","    model_classifier_federated.eval()\n","    for data,target in val_dataloader:\n","        data = data\n","        target = target\n","        optimizer_federated.zero_grad()\n","\n","        output = model_classifier_federated(data)\n","        loss = criterion_federated(output,target)\n","        _,pred = torch.max(output,1)\n","\n","        running_loss += loss.item() * data.size(0)\n","        running_corrects += torch.sum(pred == target.data)\n","\n","    epoch_loss = running_loss / test_x.shape[0]\n","    epoch_acc = running_corrects.double() / test_x.shape[0]\n","\n","\n","\n","    print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","\n"],"metadata":{"id":"EewAp9VIR13A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 25\n","\n","model_classifier_central = CNNModel()\n","optimizer_central = torch.optim.SGD(model_classifier_central.parameters(),lr = 0.01, momentum = 0.9) # keeping hyperparameters same\n","criterion_central = nn.CrossEntropyLoss()\n","\n","# model_classifier_central = model_classifier_central\n","\n","for epoch in range(epochs):\n","    running_loss = 0.0\n","    running_corrects = 0\n","    model_classifier_central.train()\n","\n","    for data,target in train_dataloader:\n","        data = data\n","        target = target\n","        optimizer_central.zero_grad()\n","\n","        output = model_classifier_central(data)\n","        loss = criterion_central(output,target)\n","        _,preds = torch.max(output,1)\n","\n","        loss.backward()\n","        optimizer_central.step()\n","\n","        running_loss += loss.item() * data.size(0)\n","        running_corrects += torch.sum(preds == target.data)\n","\n","    epoch_loss = running_loss / train_x.shape[0]\n","    epoch_acc = running_corrects.double() / train_x.shape[0]\n","\n","    print(epoch)\n","    print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    running_loss = 0.0\n","    running_corrects = 0\n","    model_classifier_central.eval()\n","    for data,target in val_dataloader:\n","\n","        data = data\n","        target = target\n","        optimizer_central.zero_grad()\n","\n","        output = model_classifier_central(data)\n","        loss = criterion_central(output,target)\n","        _,preds = torch.max(output,1)\n","\n","        running_loss += loss.item() * data.size(0)\n","        running_corrects += torch.sum(preds == target.data)\n","\n","    epoch_loss = running_loss / test_x.shape[0]\n","    epoch_acc = running_corrects.double() / test_x.shape[0]\n","\n","\n","    print(f'Val Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n"],"metadata":{"id":"osgVL578IMro","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5bac4f08-254b-4351-b7bb-35f3c6f30f80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","Train Loss: 1.6145 Acc: 0.4090\n","Val Loss: 1.4393 Acc: 0.4900\n","1\n","Train Loss: 1.3770 Acc: 0.5113\n","Val Loss: 1.4070 Acc: 0.5085\n"]}]}]}